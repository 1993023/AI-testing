{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import gensim\n",
    "from gensim import corpora,models,similarities\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"Mock_data_combined.csv\",encoding=\"unicode_escape\")\n",
    "df.head()\n",
    "df1=df[[\"Code Chunck\",\"Indicator\"]]\n",
    "df1[\"Indicator\"]=df['Indicator'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientmodel():\n",
    "    # df.columns.tolist()\n",
    "    #Text Normalization\n",
    "    tokenized_case = df1['Code Chunck'].apply(lambda x: x.split())\n",
    "    bow_vectorizer = CountVectorizer(max_df =0.90,min_df=2,max_features=1000,stop_words='english')\n",
    "    bow=bow_vectorizer.fit_transform(df1['Code Chunck'])\n",
    "#     bow.shape\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_df =0.90,min_df=2,max_features=1000,stop_words='english')\n",
    "    tfidf = tfidf_vectorizer.fit_transform(df1['Code Chunck'])\n",
    "    wordvec_arrays=np.zeros((len(tokenized_case),100))\n",
    "    for i in range(len(tokenized_case)):\n",
    "        wordvec_arrays[i,:]=word_vector(tokenized_case[i],100)\n",
    "        wordvec_df = pd.DataFrame(wordvec_arrays)\n",
    "    print(wordvec_df.shape)\n",
    "    return wordvec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_vector(tokens,size):\n",
    "    tokenized_case = df1['Code Chunck'].apply(lambda x: x.split())#tokenizing\n",
    "    model_w2v = gensim.models.Word2Vec(tokenized_case,size=100,window=5,min_count=2,sg=1,hs=0,negative=10,workers=2,seed=34)\n",
    "    model_w2v.train(tokenized_case,total_examples = len(df1['Code Chunck']),epochs=20)\n",
    "#     model_w2v.wv.most_similar(positive='assert')\n",
    "#     len(model_w2v['assert'])\n",
    "    vec= np.zeros(size).reshape(1,size)\n",
    "    count=0.\n",
    "    for word in tokens:\n",
    "        try:\n",
    "            vec +=model_w2v[word].reshape((1,size))\n",
    "            count+=1.\n",
    "        except KeyError:\n",
    "            continue\n",
    "    if count!=0:\n",
    "        vec/=count\n",
    "    return vec       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, ensemble\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 100)\n"
     ]
    }
   ],
   "source": [
    "wordvec_df=gradientmodel()\n",
    "train_df=wordvec_df\n",
    "x=train_df\n",
    "target_df=df1[\"Indicator\"]\n",
    "y=target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6   \\\n",
      "16 -0.031750 -0.165393 -0.063892  0.223427 -0.184531  0.039789  0.087326   \n",
      "40 -0.036628 -0.178954 -0.081839  0.225662 -0.177020  0.057020  0.082684   \n",
      "25 -0.032898 -0.181955 -0.060466  0.215362 -0.184004  0.040459  0.073999   \n",
      "42 -0.036485 -0.178939 -0.081701  0.225218 -0.176642  0.056809  0.082460   \n",
      "46 -0.037283 -0.188793 -0.085202  0.230476 -0.172689  0.058773  0.083873   \n",
      "4  -0.033975 -0.180698 -0.077421  0.232476 -0.181674  0.046822  0.080951   \n",
      "44 -0.034225 -0.173666 -0.079974  0.216560 -0.161604  0.055475  0.075592   \n",
      "3  -0.040758 -0.185844 -0.068520  0.228680 -0.179047  0.035842  0.079590   \n",
      "19 -0.028582 -0.172913 -0.064459  0.206998 -0.169708  0.045127  0.079046   \n",
      "20 -0.028582 -0.172913 -0.064459  0.206998 -0.169708  0.045127  0.079046   \n",
      "22 -0.036078 -0.195108 -0.075694  0.239113 -0.187989  0.040592  0.092160   \n",
      "49 -0.034344 -0.171718 -0.079291  0.212745 -0.168440  0.051515  0.075622   \n",
      "17 -0.032149 -0.170779 -0.065445  0.229873 -0.189401  0.041396  0.089059   \n",
      "27 -0.036551 -0.173363 -0.075490  0.218851 -0.172987  0.045126  0.078439   \n",
      "38 -0.034210 -0.174841 -0.080351  0.217989 -0.166399  0.054945  0.075466   \n",
      "26 -0.033120 -0.182149 -0.061433  0.215873 -0.183150  0.041108  0.074528   \n",
      "18 -0.032149 -0.170779 -0.065445  0.229873 -0.189401  0.041396  0.089059   \n",
      "1  -0.040702 -0.176105 -0.070190  0.219445 -0.164112  0.036718  0.076108   \n",
      "2  -0.039443 -0.185631 -0.068451  0.228159 -0.179252  0.035611  0.079428   \n",
      "14 -0.031489 -0.166646 -0.064912  0.223805 -0.185192  0.040710  0.087733   \n",
      "30 -0.031447 -0.170455 -0.077189  0.213440 -0.167333  0.047316  0.076358   \n",
      "43 -0.034205 -0.173398 -0.079631  0.216445 -0.161333  0.055381  0.075528   \n",
      "41 -0.036898 -0.179943 -0.082400  0.227469 -0.177985  0.057791  0.083581   \n",
      "45 -0.037396 -0.189306 -0.085336  0.230885 -0.172949  0.058731  0.084006   \n",
      "11 -0.034359 -0.181327 -0.078394  0.232295 -0.181229  0.048524  0.080899   \n",
      "\n",
      "          7         8         9   ...        90        91        92        93  \\\n",
      "16 -0.056234  0.114561 -0.077687  ... -0.002765  0.001126  0.030048 -0.221862   \n",
      "40 -0.059068  0.117270 -0.069669  ...  0.003471 -0.010339  0.021599 -0.222206   \n",
      "25 -0.042601  0.118680 -0.095456  ...  0.012277  0.009796  0.044001 -0.227479   \n",
      "42 -0.058545  0.117149 -0.070109  ...  0.003368 -0.010158  0.022068 -0.222253   \n",
      "46 -0.052127  0.128493 -0.087031  ...  0.009699 -0.006248  0.036207 -0.236155   \n",
      "4  -0.058597  0.126366 -0.087828  ...  0.001679  0.004086  0.033789 -0.232590   \n",
      "44 -0.048343  0.118375 -0.078064  ...  0.004021 -0.009113  0.031162 -0.222148   \n",
      "3  -0.053189  0.132022 -0.076028  ...  0.005821 -0.002840  0.051665 -0.232778   \n",
      "19 -0.048597  0.121176 -0.088665  ...  0.003212  0.003713  0.039076 -0.217872   \n",
      "20 -0.048597  0.121176 -0.088665  ...  0.003212  0.003713  0.039076 -0.217872   \n",
      "22 -0.059219  0.133092 -0.087717  ...  0.005956 -0.009459  0.042156 -0.242311   \n",
      "49 -0.049381  0.113955 -0.076501  ...  0.003075 -0.010689  0.026878 -0.220270   \n",
      "17 -0.055986  0.117215 -0.079028  ... -0.002575  0.000378  0.029456 -0.222509   \n",
      "27 -0.057183  0.119530 -0.080325  ...  0.001022 -0.000265  0.032377 -0.226115   \n",
      "38 -0.051243  0.114991 -0.074930  ...  0.003312 -0.011636  0.026287 -0.222238   \n",
      "26 -0.043418  0.119126 -0.094646  ...  0.011590  0.008881  0.043185 -0.227401   \n",
      "18 -0.055986  0.117215 -0.079028  ... -0.002575  0.000378  0.029456 -0.222509   \n",
      "1  -0.048236  0.125738 -0.077074  ...  0.010477 -0.001361  0.047583 -0.223051   \n",
      "2  -0.053070  0.131757 -0.075648  ...  0.005486 -0.002991  0.051787 -0.231689   \n",
      "14 -0.056351  0.115714 -0.077611  ... -0.003469  0.001550  0.029587 -0.221851   \n",
      "30 -0.047490  0.116570 -0.075385  ...  0.003991 -0.000784  0.031662 -0.214191   \n",
      "43 -0.048041  0.118204 -0.078389  ...  0.004115 -0.008843  0.031399 -0.222192   \n",
      "41 -0.060032  0.117794 -0.069606  ...  0.004031 -0.009953  0.020879 -0.222579   \n",
      "45 -0.052298  0.128882 -0.087246  ...  0.009774 -0.006073  0.036255 -0.236544   \n",
      "11 -0.058048  0.125599 -0.087496  ...  0.002326  0.002761  0.033141 -0.232932   \n",
      "\n",
      "          94        95        96        97        98        99  \n",
      "16  0.168102 -0.044451 -0.063113 -0.046825  0.086778 -0.008882  \n",
      "40  0.180907 -0.018422 -0.063836 -0.040992  0.074190 -0.021257  \n",
      "25  0.179424 -0.031139 -0.065844 -0.041460  0.079629 -0.018043  \n",
      "42  0.180814 -0.018625 -0.063471 -0.040644  0.073943 -0.021285  \n",
      "46  0.189861 -0.031235 -0.062522 -0.037542  0.078555 -0.017679  \n",
      "4   0.176018 -0.037447 -0.063382 -0.046594  0.086454 -0.014525  \n",
      "44  0.179347 -0.022717 -0.058747 -0.032638  0.070108 -0.019587  \n",
      "3   0.160175 -0.046463 -0.069995 -0.048627  0.087018 -0.023811  \n",
      "19  0.169806 -0.033760 -0.058014 -0.042396  0.069243 -0.023029  \n",
      "20  0.169806 -0.033760 -0.058014 -0.042396  0.069243 -0.023029  \n",
      "22  0.189305 -0.047680 -0.076217 -0.044735  0.087155 -0.013691  \n",
      "49  0.174979 -0.023628 -0.059428 -0.036719  0.070684 -0.017777  \n",
      "17  0.174128 -0.045834 -0.062616 -0.048520  0.088316 -0.008935  \n",
      "27  0.171511 -0.032576 -0.064250 -0.040825  0.078016 -0.017485  \n",
      "38  0.179908 -0.018585 -0.059867 -0.034521  0.070520 -0.020721  \n",
      "26  0.179293 -0.031069 -0.065462 -0.041080  0.079261 -0.018072  \n",
      "18  0.174128 -0.045834 -0.062616 -0.048520  0.088316 -0.008935  \n",
      "1   0.157958 -0.041775 -0.067131 -0.040650  0.077558 -0.021123  \n",
      "2   0.160292 -0.046768 -0.070315 -0.048632  0.087853 -0.023588  \n",
      "14  0.169163 -0.044580 -0.062853 -0.046632  0.086991 -0.008890  \n",
      "30  0.172033 -0.031599 -0.063357 -0.038063  0.077738 -0.015878  \n",
      "43  0.179106 -0.022975 -0.058553 -0.032470  0.070254 -0.019238  \n",
      "41  0.181686 -0.018754 -0.064396 -0.041360  0.074995 -0.021278  \n",
      "45  0.189964 -0.031509 -0.062662 -0.037606  0.078830 -0.017601  \n",
      "11  0.177304 -0.036404 -0.063363 -0.045696  0.085522 -0.014933  \n",
      "\n",
      "[25 rows x 100 columns]\n",
      "16    1\n",
      "40    0\n",
      "25    1\n",
      "42    1\n",
      "46    1\n",
      "4     1\n",
      "44    1\n",
      "3     1\n",
      "19    1\n",
      "20    0\n",
      "22    0\n",
      "49    0\n",
      "17    1\n",
      "27    1\n",
      "38    1\n",
      "26    0\n",
      "18    0\n",
      "1     1\n",
      "2     0\n",
      "14    1\n",
      "30    1\n",
      "43    0\n",
      "41    1\n",
      "45    0\n",
      "11    0\n",
      "Name: Indicator, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "x_training_data, x_test_data, y_training_data, y_test_data = train_test_split(x, y, test_size = 0.5)\n",
    "# print(x_training_data)\n",
    "print(x_test_data)\n",
    "# print(y_training_data)\n",
    "print(y_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbclf = ensemble.GradientBoostingClassifier()\n",
    "gbclf.fit(x_training_data, y_training_data)\n",
    "predictions_lg= gbclf.predict(x_test_data)\n",
    "predictions_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GB_Predicted_Indicator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    GB_Predicted_Indicator\n",
       "16                       0\n",
       "40                       1\n",
       "25                       1\n",
       "42                       1\n",
       "46                       1\n",
       "4                        0\n",
       "44                       1\n",
       "3                        0\n",
       "19                       0\n",
       "20                       0\n",
       "22                       1\n",
       "49                       1\n",
       "17                       0\n",
       "27                       0\n",
       "38                       0\n",
       "26                       1\n",
       "18                       0\n",
       "1                        0\n",
       "2                        0\n",
       "14                       0\n",
       "30                       0\n",
       "43                       1\n",
       "41                       1\n",
       "45                       1\n",
       "11                       0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yprd_df=pd.DataFrame(predictions_lg,index=list(x_test_data.index.values))\n",
    "yprd_df=yprd_df.rename(columns={0:\"GB_Predicted_Indicator\"})\n",
    "yprd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1=df1.join(yprd_df)\n",
    "# df1.to_csv(\"gb_prediction.csv\",index=False)\n",
    "\n",
    "\n",
    "final_df=df1.iloc[list(x_test_data.index.values),:]\n",
    "final_df=pd.concat([final_df,yprd_df],axis=1)\n",
    "final_df\n",
    "final_df.to_csv(\"gb_prediction.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbclf.score(x_test_data, y_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = reg.predict(x_test_data)\n",
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.05\n",
      "Accuracy score (training): 0.760\n",
      "Accuracy score (validation): 0.360\n",
      "Learning rate:  0.075\n",
      "Accuracy score (training): 0.760\n",
      "Accuracy score (validation): 0.360\n",
      "Learning rate:  0.1\n",
      "Accuracy score (training): 0.760\n",
      "Accuracy score (validation): 0.360\n",
      "Learning rate:  0.25\n",
      "Accuracy score (training): 0.760\n",
      "Accuracy score (validation): 0.360\n",
      "Learning rate:  0.5\n",
      "Accuracy score (training): 0.760\n",
      "Accuracy score (validation): 0.360\n",
      "Learning rate:  0.75\n",
      "Accuracy score (training): 0.760\n",
      "Accuracy score (validation): 0.360\n",
      "Learning rate:  1\n",
      "Accuracy score (training): 0.760\n",
      "Accuracy score (validation): 0.360\n"
     ]
    }
   ],
   "source": [
    "lr_list = [0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1]\n",
    "\n",
    "for learning_rate in lr_list:\n",
    "    gb_clf = GradientBoostingClassifier(n_estimators=20, learning_rate=learning_rate, max_features=2, max_depth=2, random_state=0)\n",
    "    gb_clf.fit(x_training_data, y_training_data)\n",
    "\n",
    "    print(\"Learning rate: \", learning_rate)\n",
    "    print(\"Accuracy score (training): {0:.3f}\".format(gb_clf.score(x_training_data, y_training_data)))\n",
    "    print(\"Accuracy score (validation): {0:.3f}\".format(gb_clf.score(x_test_data, y_test_data)))\n",
    "#     print(\"Accuracy score (prediction): {0:.3f}\".format(gb_clf.score(y_test_data, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 5  5]\n",
      " [11  4]]\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.50      0.38        10\n",
      "           1       0.44      0.27      0.33        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.38      0.38      0.36        25\n",
      "weighted avg       0.39      0.36      0.35        25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(n_estimators=20, learning_rate = 0.5, max_features=2, max_depth = 2, random_state = 0)\n",
    "gb.fit(x_training_data, y_training_data)\n",
    "predictions = gb.predict(x_test_data)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_data, predictions))\n",
    "print()\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test_data, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
