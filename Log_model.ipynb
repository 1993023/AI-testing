{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import gensim\n",
    "from gensim import corpora,models,similarities\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import gensim\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"Mock_data_combined.csv\",encoding=\"unicode_escape\")\n",
    "df.head()\n",
    "df1=df[[\"Code Chunck\",\"Indicator\"]]\n",
    "df1[\"Indicator\"]=df['Indicator'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticmodel():\n",
    "    # df.columns.tolist()\n",
    "    #Text Normalization\n",
    "    tokenized_case = df1['Code Chunck'].apply(lambda x: x.split())\n",
    "    bow_vectorizer = CountVectorizer(max_df =0.90,min_df=2,max_features=1000,stop_words='english')\n",
    "    bow=bow_vectorizer.fit_transform(df1['Code Chunck'])\n",
    "#     bow.shape\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_df =0.90,min_df=2,max_features=1000,stop_words='english')\n",
    "    tfidf = tfidf_vectorizer.fit_transform(df1['Code Chunck'])\n",
    "    wordvec_arrays=np.zeros((len(tokenized_case),100))\n",
    "    for i in range(len(tokenized_case)):\n",
    "        wordvec_arrays[i,:]=word_vector(tokenized_case[i],100)\n",
    "        wordvec_df = pd.DataFrame(wordvec_arrays)\n",
    "    print(wordvec_df.shape)\n",
    "    return wordvec_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_vector(tokens,size):\n",
    "    tokenized_case = df1['Code Chunck'].apply(lambda x: x.split())#tokenizing\n",
    "    model_w2v = gensim.models.Word2Vec(tokenized_case,size=100,window=5,min_count=2,sg=1,hs=0,negative=10,workers=2,seed=34)\n",
    "    model_w2v.train(tokenized_case,total_examples = len(df1['Code Chunck']),epochs=20)\n",
    "#     model_w2v.wv.most_similar(positive='assert')\n",
    "#     len(model_w2v['assert'])\n",
    "    vec= np.zeros(size).reshape(1,size)\n",
    "    count=0.\n",
    "    for word in tokens:\n",
    "        try:\n",
    "            vec +=model_w2v[word].reshape((1,size))\n",
    "            count+=1.\n",
    "        except KeyError:\n",
    "            continue\n",
    "    if count!=0:\n",
    "        vec/=count\n",
    "    return vec   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 100)\n"
     ]
    }
   ],
   "source": [
    "wordvec_df=logisticmodel()\n",
    "train_df=wordvec_df\n",
    "x=train_df\n",
    "target_df=df1[\"Indicator\"]\n",
    "y=target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6   \\\n",
      "2  -0.160723 -0.187765 -0.001024 -0.064838  0.009269  0.052114 -0.041524   \n",
      "34 -0.154637 -0.194553 -0.012597 -0.066328  0.006100  0.054438 -0.014154   \n",
      "18 -0.162668 -0.188431 -0.013953 -0.054505  0.006854  0.043403 -0.028824   \n",
      "40 -0.163734 -0.182853 -0.005693 -0.057620 -0.001678  0.044589  0.004949   \n",
      "14 -0.158917 -0.184059 -0.014213 -0.055137  0.006396  0.042319 -0.029948   \n",
      "28 -0.157175 -0.179108 -0.008549 -0.056865 -0.002930  0.043000 -0.010646   \n",
      "33 -0.154637 -0.194553 -0.012597 -0.066328  0.006100  0.054438 -0.014154   \n",
      "48 -0.150637 -0.175013 -0.010964 -0.054813 -0.006758  0.045131  0.004224   \n",
      "47 -0.164422 -0.193039 -0.006680 -0.060504 -0.010423  0.044304  0.001090   \n",
      "20 -0.147663 -0.180210 -0.003192 -0.054821 -0.002717  0.048544 -0.006437   \n",
      "8  -0.138299 -0.160975 -0.004621 -0.047827  0.005883  0.038484 -0.021642   \n",
      "38 -0.155597 -0.177174 -0.008024 -0.055936 -0.006313  0.044980  0.007553   \n",
      "49 -0.150637 -0.175013 -0.010964 -0.054813 -0.006758  0.045131  0.004224   \n",
      "32 -0.148088 -0.173598 -0.008099 -0.056860 -0.005019  0.042603 -0.001524   \n",
      "37 -0.155099 -0.176991 -0.008014 -0.055458 -0.005893  0.045270  0.007294   \n",
      "39 -0.163011 -0.182344 -0.006062 -0.057267 -0.001825  0.044999  0.005333   \n",
      "36 -0.161804 -0.204017 -0.008177 -0.064894  0.002691  0.058550 -0.019454   \n",
      "5  -0.173707 -0.205315 -0.007744 -0.060220 -0.007210  0.056519 -0.012944   \n",
      "0  -0.160679 -0.188096 -0.000620 -0.064636  0.009024  0.049608 -0.043079   \n",
      "31 -0.148088 -0.173598 -0.008099 -0.056860 -0.005019  0.042603 -0.001524   \n",
      "10 -0.160733 -0.187349 -0.000344 -0.064173  0.009085  0.051615 -0.041080   \n",
      "16 -0.158687 -0.184092 -0.014371 -0.054002  0.006710  0.040853 -0.030486   \n",
      "11 -0.162815 -0.186076 -0.009297 -0.057696 -0.003804  0.043889 -0.023528   \n",
      "46 -0.167500 -0.196943 -0.006474 -0.061114 -0.011844  0.044633  0.000387   \n",
      "44 -0.155864 -0.179844 -0.008102 -0.057818 -0.009261  0.042563  0.006512   \n",
      "\n",
      "          7         8         9   ...        90        91        92        93  \\\n",
      "2   0.062323 -0.028539  0.270439  ...  0.112230 -0.406477  0.058254 -0.184446   \n",
      "34  0.067767 -0.046670  0.288518  ...  0.119520 -0.400118  0.069580 -0.203353   \n",
      "18  0.068000 -0.042322  0.276509  ...  0.111232 -0.387253  0.060180 -0.202371   \n",
      "40  0.068515 -0.034905  0.260915  ...  0.129893 -0.395552  0.077497 -0.186753   \n",
      "14  0.065878 -0.038728  0.271898  ...  0.109236 -0.379599  0.056518 -0.197952   \n",
      "28  0.064479 -0.033935  0.258800  ...  0.110852 -0.382374  0.061730 -0.188761   \n",
      "33  0.067767 -0.046670  0.288518  ...  0.119520 -0.400118  0.069580 -0.203353   \n",
      "48  0.066586 -0.034128  0.246964  ...  0.119929 -0.373947  0.074813 -0.176585   \n",
      "47  0.072691 -0.037268  0.260531  ...  0.117889 -0.395852  0.073258 -0.186055   \n",
      "20  0.060637 -0.043083  0.253469  ...  0.105632 -0.379409  0.072717 -0.176843   \n",
      "8   0.055937 -0.029566  0.231848  ...  0.097300 -0.336730  0.051399 -0.164422   \n",
      "38  0.068261 -0.037244  0.249552  ...  0.126595 -0.378941  0.079479 -0.174552   \n",
      "49  0.066586 -0.034128  0.246964  ...  0.119929 -0.373947  0.074813 -0.176585   \n",
      "32  0.063545 -0.034390  0.247370  ...  0.116354 -0.369625  0.068976 -0.175921   \n",
      "37  0.067966 -0.036963  0.249361  ...  0.126596 -0.379067  0.079368 -0.175216   \n",
      "39  0.068286 -0.035099  0.260448  ...  0.129982 -0.394441  0.077778 -0.186238   \n",
      "36  0.068872 -0.043743  0.293766  ...  0.122198 -0.410918  0.069957 -0.210632   \n",
      "5   0.073900 -0.052248  0.292080  ...  0.117304 -0.433316  0.080537 -0.205655   \n",
      "0   0.062602 -0.019939  0.261126  ...  0.111759 -0.399654  0.052353 -0.180615   \n",
      "31  0.063545 -0.034390  0.247370  ...  0.116354 -0.369625  0.068976 -0.175921   \n",
      "10  0.062092 -0.028476  0.270080  ...  0.113516 -0.406478  0.058303 -0.183137   \n",
      "16  0.066233 -0.038437  0.270765  ...  0.107827 -0.378519  0.056136 -0.196958   \n",
      "11  0.070608 -0.037324  0.272463  ...  0.116145 -0.396281  0.067526 -0.196422   \n",
      "46  0.073879 -0.039149  0.266079  ...  0.119444 -0.402850  0.073438 -0.191143   \n",
      "44  0.069551 -0.037676  0.247683  ...  0.121855 -0.376628  0.076337 -0.173682   \n",
      "\n",
      "          94        95        96        97        98        99  \n",
      "2  -0.165295 -0.312828  0.125761 -0.129965  0.164628  0.020614  \n",
      "34 -0.181324 -0.313630  0.119243 -0.147530  0.174469  0.052178  \n",
      "18 -0.173899 -0.303350  0.105320 -0.124235  0.166875  0.038597  \n",
      "40 -0.181816 -0.293938  0.126594 -0.145287  0.145506  0.042554  \n",
      "14 -0.170505 -0.298370  0.103788 -0.119097  0.164336  0.036877  \n",
      "28 -0.177637 -0.295629  0.118324 -0.135980  0.155256  0.034736  \n",
      "33 -0.181324 -0.313630  0.119243 -0.147530  0.174469  0.052178  \n",
      "48 -0.173448 -0.287303  0.118620 -0.139572  0.143787  0.041818  \n",
      "47 -0.183050 -0.307763  0.127480 -0.148596  0.151073  0.040180  \n",
      "20 -0.172441 -0.295186  0.111491 -0.136252  0.144762  0.036464  \n",
      "8  -0.147088 -0.257632  0.102152 -0.113246  0.132302  0.028924  \n",
      "38 -0.173210 -0.290294  0.119977 -0.142417  0.142037  0.042966  \n",
      "49 -0.173448 -0.287303  0.118620 -0.139572  0.143787  0.041818  \n",
      "32 -0.170992 -0.284260  0.112316 -0.136218  0.146120  0.038431  \n",
      "37 -0.173350 -0.289652  0.119997 -0.142502  0.142090  0.043317  \n",
      "39 -0.181368 -0.293712  0.126248 -0.145051  0.145635  0.043046  \n",
      "36 -0.186421 -0.326673  0.119152 -0.150587  0.177101  0.048458  \n",
      "5  -0.187575 -0.331877  0.120609 -0.154657  0.169672  0.043813  \n",
      "0  -0.164205 -0.309568  0.129329 -0.128168  0.163424  0.018332  \n",
      "31 -0.170992 -0.284260  0.112316 -0.136218  0.146120  0.038431  \n",
      "10 -0.165458 -0.311084  0.125410 -0.129854  0.164437  0.022131  \n",
      "16 -0.169355 -0.297965  0.103150 -0.116984  0.163294  0.035239  \n",
      "11 -0.180293 -0.302325  0.112874 -0.135364  0.160096  0.039150  \n",
      "46 -0.186403 -0.313725  0.128702 -0.150977  0.154252  0.041533  \n",
      "44 -0.173663 -0.291075  0.119765 -0.141974  0.141772  0.041355  \n",
      "\n",
      "[25 rows x 100 columns]\n",
      "-----------------\n",
      "          0         1         2         3         4         5         6   \\\n",
      "45 -0.167852 -0.197556 -0.006374 -0.061359 -0.011815  0.044832  0.000066   \n",
      "23 -0.168481 -0.202640  0.003201 -0.065773  0.002043  0.044380 -0.027847   \n",
      "43 -0.155646 -0.179958 -0.007847 -0.057880 -0.009573  0.042510  0.006298   \n",
      "15 -0.158917 -0.184059 -0.014213 -0.055137  0.006396  0.042319 -0.029948   \n",
      "9  -0.152385 -0.178850 -0.001669 -0.062090  0.004083  0.045023 -0.028567   \n",
      "12 -0.173707 -0.205315 -0.007744 -0.060220 -0.007210  0.056519 -0.012944   \n",
      "29 -0.146800 -0.173429 -0.003565 -0.058645 -0.004276  0.045861 -0.006441   \n",
      "19 -0.147663 -0.180210 -0.003192 -0.054821 -0.002717  0.048544 -0.006437   \n",
      "30 -0.146800 -0.173429 -0.003565 -0.058645 -0.004276  0.045861 -0.006441   \n",
      "6  -0.173606 -0.198523 -0.008020 -0.063964 -0.001056  0.051464 -0.017719   \n",
      "7  -0.138299 -0.160975 -0.004621 -0.047827  0.005883  0.038484 -0.021642   \n",
      "4  -0.162385 -0.185932 -0.009522 -0.057959 -0.002604  0.043824 -0.027041   \n",
      "13 -0.171504 -0.196427 -0.008605 -0.063071 -0.001207  0.051340 -0.016479   \n",
      "1  -0.156046 -0.182337 -0.001748 -0.063399  0.003349  0.045896 -0.029106   \n",
      "21 -0.173545 -0.209618 -0.003079 -0.063036 -0.002992  0.055143 -0.017264   \n",
      "26 -0.158865 -0.185695 -0.005024 -0.061753 -0.012029  0.051241 -0.000265   \n",
      "25 -0.158791 -0.185698 -0.005185 -0.061775 -0.012306  0.051381  0.000005   \n",
      "22 -0.174829 -0.210535 -0.002770 -0.063478 -0.003805  0.055552 -0.017084   \n",
      "42 -0.163430 -0.182488 -0.005878 -0.057486 -0.002030  0.044581  0.004579   \n",
      "35 -0.161804 -0.204017 -0.008177 -0.064894  0.002691  0.058550 -0.019454   \n",
      "41 -0.165101 -0.184166 -0.004685 -0.058439 -0.001336  0.044018  0.005722   \n",
      "24 -0.168481 -0.202640  0.003201 -0.065773  0.002043  0.044380 -0.027847   \n",
      "3  -0.161093 -0.188645 -0.000873 -0.064946  0.009185  0.052334 -0.041589   \n",
      "17 -0.162668 -0.188431 -0.013953 -0.054505  0.006854  0.043403 -0.028824   \n",
      "27 -0.157175 -0.179108 -0.008549 -0.056865 -0.002930  0.043000 -0.010646   \n",
      "\n",
      "          7         8         9   ...        90        91        92        93  \\\n",
      "45  0.073891 -0.039122  0.266653  ...  0.119275 -0.403753  0.073470 -0.191653   \n",
      "23  0.070831 -0.051942  0.299791  ...  0.113362 -0.435500  0.073169 -0.222520   \n",
      "43  0.069419 -0.037646  0.247689  ...  0.121600 -0.376311  0.076278 -0.173584   \n",
      "15  0.065878 -0.038728  0.271898  ...  0.109236 -0.379599  0.056518 -0.197952   \n",
      "9   0.064384 -0.024174  0.250794  ...  0.109839 -0.381777  0.058194 -0.172697   \n",
      "12  0.073900 -0.052248  0.292080  ...  0.117304 -0.433316  0.080537 -0.205655   \n",
      "29  0.063305 -0.036980  0.251526  ...  0.111194 -0.368306  0.064535 -0.180807   \n",
      "19  0.060637 -0.043083  0.253469  ...  0.105632 -0.379409  0.072717 -0.176843   \n",
      "30  0.063305 -0.036980  0.251526  ...  0.111194 -0.368306  0.064535 -0.180807   \n",
      "6   0.074722 -0.037177  0.290182  ...  0.124998 -0.416411  0.063002 -0.209723   \n",
      "7   0.055937 -0.029566  0.231848  ...  0.097300 -0.336730  0.051399 -0.164422   \n",
      "4   0.070099 -0.037233  0.273551  ...  0.115033 -0.395828  0.066387 -0.196790   \n",
      "13  0.073299 -0.037186  0.286512  ...  0.124164 -0.411963  0.064090 -0.205995   \n",
      "1   0.065129 -0.024097  0.254385  ...  0.111019 -0.386751  0.056915 -0.177019   \n",
      "21  0.073692 -0.044642  0.303892  ...  0.118661 -0.424731  0.073757 -0.209897   \n",
      "26  0.068025 -0.039090  0.258907  ...  0.105042 -0.396188  0.072346 -0.186040   \n",
      "25  0.067696 -0.039131  0.258843  ...  0.104226 -0.396226  0.072299 -0.185869   \n",
      "22  0.074097 -0.044865  0.304851  ...  0.119394 -0.427177  0.074326 -0.210360   \n",
      "42  0.068231 -0.034875  0.260260  ...  0.129260 -0.394677  0.077621 -0.186359   \n",
      "35  0.068872 -0.043743  0.293766  ...  0.122198 -0.410918  0.069957 -0.210632   \n",
      "41  0.069594 -0.034611  0.262324  ...  0.130901 -0.398609  0.077298 -0.188824   \n",
      "24  0.070831 -0.051942  0.299791  ...  0.113362 -0.435500  0.073169 -0.222520   \n",
      "3   0.062894 -0.027834  0.270188  ...  0.113134 -0.406934  0.057362 -0.184622   \n",
      "17  0.068000 -0.042322  0.276509  ...  0.111232 -0.387253  0.060180 -0.202371   \n",
      "27  0.064479 -0.033935  0.258800  ...  0.110852 -0.382374  0.061730 -0.188761   \n",
      "\n",
      "          94        95        96        97        98        99  \n",
      "45 -0.186866 -0.314319  0.129035 -0.151137  0.154625  0.041448  \n",
      "23 -0.188226 -0.342626  0.132119 -0.172315  0.168614  0.050585  \n",
      "43 -0.173282 -0.291037  0.119772 -0.141711  0.141666  0.041211  \n",
      "15 -0.170505 -0.298370  0.103788 -0.119097  0.164336  0.036877  \n",
      "9  -0.159984 -0.294083  0.121656 -0.128329  0.153848  0.022399  \n",
      "12 -0.187575 -0.331877  0.120609 -0.154657  0.169672  0.043813  \n",
      "29 -0.167541 -0.285463  0.110933 -0.136961  0.147663  0.041608  \n",
      "19 -0.172441 -0.295186  0.111491 -0.136252  0.144762  0.036464  \n",
      "30 -0.167541 -0.285463  0.110933 -0.136961  0.147663  0.041608  \n",
      "6  -0.189236 -0.326350  0.125304 -0.150657  0.169868  0.040155  \n",
      "7  -0.147088 -0.257632  0.102152 -0.113246  0.132302  0.028924  \n",
      "4  -0.179294 -0.301915  0.111223 -0.133431  0.161164  0.038305  \n",
      "13 -0.186951 -0.323083  0.124118 -0.149092  0.167432  0.040171  \n",
      "1  -0.163700 -0.300018  0.124994 -0.130970  0.157007  0.022583  \n",
      "21 -0.180760 -0.324774  0.113095 -0.142914  0.184183  0.037870  \n",
      "26 -0.181467 -0.312539  0.113191 -0.148742  0.153741  0.041106  \n",
      "25 -0.181678 -0.313544  0.112629 -0.149099  0.154220  0.041009  \n",
      "22 -0.180881 -0.325852  0.114180 -0.143188  0.184895  0.037382  \n",
      "42 -0.181407 -0.293891  0.126133 -0.144913  0.145336  0.042731  \n",
      "35 -0.186421 -0.326673  0.119152 -0.150587  0.177101  0.048458  \n",
      "41 -0.183862 -0.294807  0.128242 -0.146365  0.145973  0.042530  \n",
      "24 -0.188226 -0.342626  0.132119 -0.172315  0.168614  0.050585  \n",
      "3  -0.165973 -0.313443  0.127255 -0.130315  0.165391  0.020477  \n",
      "17 -0.173899 -0.303350  0.105320 -0.124235  0.166875  0.038597  \n",
      "27 -0.177637 -0.295629  0.118324 -0.135980  0.155256  0.034736  \n",
      "\n",
      "[25 rows x 100 columns]\n"
     ]
    }
   ],
   "source": [
    "x_training_data, x_test_data, y_training_data, y_test_data = train_test_split(x, y, test_size = 0.5)\n",
    "print(x_training_data)\n",
    "print(\"-----------------\")\n",
    "print(x_test_data)\n",
    "# print(y_training_data)\n",
    "# print(y_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lg = LogisticRegression()\n",
    "model_lg.fit(x_training_data, y_training_data)\n",
    "predictions_lg= model_lg.predict(x_test_data)\n",
    "predictions_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic_Predicted_Indicator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Logistic_Predicted_Indicator\n",
       "45                             0\n",
       "23                             0\n",
       "43                             0\n",
       "15                             0\n",
       "9                              0\n",
       "12                             0\n",
       "29                             0\n",
       "19                             0\n",
       "30                             0\n",
       "6                              0\n",
       "7                              0\n",
       "4                              0\n",
       "13                             0\n",
       "1                              0\n",
       "21                             0\n",
       "26                             0\n",
       "25                             0\n",
       "22                             0\n",
       "42                             0\n",
       "35                             0\n",
       "41                             0\n",
       "24                             0\n",
       "3                              0\n",
       "17                             0\n",
       "27                             0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yprd_df=pd.DataFrame(predictions_lg,index=list(x_test_data.index.values))\n",
    "yprd_df=yprd_df.rename(columns={0:\"Logistic_Predicted_Indicator\"})\n",
    "yprd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1=df1.join(yprd_df)\n",
    "# df1.to_csv(\"log_prediction.csv\",index=False)\n",
    "\n",
    "final_df=df1.iloc[list(x_test_data.index.values),:]\n",
    "final_df=pd.concat([final_df,yprd_df],axis=1)\n",
    "final_df\n",
    "final_df.to_csv(\"log_prediction.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10  0]\n",
      " [15  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "F:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "F:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(y_test_data, predictions_lg)\n",
    "print(confusion_matrix(y_test_data, predictions_lg))\n",
    "y_pred = model_lg.predict(x_test_data)\n",
    "score =accuracy_score(y_test_data,y_pred)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
